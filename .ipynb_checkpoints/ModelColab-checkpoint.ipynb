{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "IxbJnxHJlqH-",
    "outputId": "0e06825f-e3ef-4845-8969-e7a933e3f286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "root_dir = \"/content/gdrive/My Drive/\"\n",
    "base_dir = root_dir + 'ML dataSets/TV Scripting'\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wntQ-zf7lqIO"
   },
   "source": [
    "Now the ML starts, above is the code for colab setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VMclfaHZlqIT",
    "outputId": "f4692da5-a888-4897-d940-1b029d1fd655"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, LSTM ,Dropout,Input\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sqC6Pxl-lqIg",
    "outputId": "94c9647f-99b8-4acc-e99d-8fc840f947fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/ML dataSets/TV Scripting/scripts-utf-8.txt\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/42339876/error-unicodedecodeerror-utf-8-codec-cant-decode-byte-0xff-in-position-0-in/42340744\n",
    "data_dir=base_dir+\"/scripts-utf-8.txt\"\n",
    "print(data_dir)\n",
    "with open(data_dir,'r',encoding=\"utf-8\") as f:\n",
    "    data=f.read()\n",
    "\n",
    "data=data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "C8w-T5vhlqIs",
    "outputId": "015d823c-f7b9-46ab-e84c-5451274f4942",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n                    \\t\\t\\t- so, what do you think? - wow.\\n it's for you, right? it's for both of us.\\n don't go away.\\n don't worry.\\n there's not enough blood left in my legs to go anywhere.\\n hey, it's charlie.\\n do your thing when you hear the beep.\\n listen, you lousy s.\\no.\\nb.\\n, i will not be treated like this.\\n either you call me, or you are gonna be very, very sorry.\\n i love you, monkey man.\\n charlie? who was that? damn telemarketers.\\n a telemarketer who calls you monkey man? i'm on some weir\""
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "59c5e40ZlqI9",
    "outputId": "daef1b6f-d8d1-4685-a790-2e344e6baa76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                    \\t\\t\\t- so, what do you think? - wow.\\n it's for you, right? it's for both of us.\\n d\""
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data[6:] \n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "keG2wGePnl0p",
    "outputId": "503212c6-29f8-47f9-d573-b71d4dba3214"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2hgloeU2o1Wh"
   },
   "outputs": [],
   "source": [
    "# data.encode('utf-8').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvUplcS4odZ4"
   },
   "outputs": [],
   "source": [
    "# data=str(data, 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "Gf1oLqDYlqJK",
    "outputId": "02f5625e-eeea-4536-900c-696c2756cd73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                    \\t\\t\\t- so, what do you think? - wow.',\n",
       " \" it's for you, right? it's for both of us.\",\n",
       " \" don't go away.\",\n",
       " \" don't worry.\",\n",
       " \" there's not enough blood left in my legs to go anywhere.\",\n",
       " \" hey, it's charlie.\",\n",
       " ' do your thing when you hear the beep.',\n",
       " ' listen, you lousy s.',\n",
       " 'o.',\n",
       " 'b.',\n",
       " ', i will not be treated like this.',\n",
       " ' either you call me, or you are gonna be very, very sorry.',\n",
       " ' i love you, monkey man.',\n",
       " ' charlie']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:400].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dN1t-FqtlqJX"
   },
   "source": [
    "We are getting S.O.B as different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pltLyJPlqJb"
   },
   "outputs": [],
   "source": [
    "punch=['.','[',']','(',')',';',':',\"'\",\"/\",'\"',',','?','*','!','-','$','%',\n",
    "       '&','\\n']\n",
    "\n",
    "for i in punch:\n",
    "    data=data.replace(i,' '+i+' ')\n",
    "data=data.replace('\\n','<newline>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "xBrPY0YqlqJn",
    "outputId": "f60a8ef5-a591-48bb-afd1-82a7eaaa2563"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                    \\t\\t\\t -  so ,  what do you think ?   -  wow .  <newline>  it ' s for you ,  right ?  it ' s for both of us .  <newline>  don ' t go away .  <newline>  don ' t worry .  <newline>  there ' s not enough blood left in my legs to go anywhere .  <newline>  hey ,  it ' s charlie .  <newline>  do your thing when you hear the beep .  <newline>  listen ,  you lousy s .  <newline> o .  <new\""
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3uCWvH5lqJz"
   },
   "outputs": [],
   "source": [
    "def get_vocab(text):\n",
    "    counter=Counter()\n",
    "    int_to_vocab=dict()\n",
    "    vocab_to_int=dict()\n",
    "    \n",
    "    for d in text.split():\n",
    "        counter[d]+=1\n",
    "    \n",
    "    index=0\n",
    "    for word in counter:\n",
    "        int_to_vocab[index]=word\n",
    "        vocab_to_int[word]=index\n",
    "        index+=1\n",
    "    \n",
    "    return counter, vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3OhnPdPlqKA"
   },
   "outputs": [],
   "source": [
    "vocab,vocab_to_int, int_to_vocab =get_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uNUQpC0zlqKL",
    "outputId": "35870a7d-7072-46b6-ec1c-580d3288ceb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size :  9000\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab size : \",len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-r1662hzlqKZ"
   },
   "source": [
    "Coverting the whole text corpus into integer corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osX280VdlqKd"
   },
   "outputs": [],
   "source": [
    "text_int=[]\n",
    "\n",
    "for word in data.split():\n",
    "    text_int.append(vocab_to_int[word])\n",
    "text_int=np.array(text_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qBtYcSPNlqKm",
    "outputId": "154fc5c3-326f-4d3a-c921-daf8ea2f29a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259916"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0w0e3Xi8lqKt"
   },
   "source": [
    "These are approximately number of words in Two and Half Men's 3 Sesaons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00cWRejDlqKu"
   },
   "source": [
    "Tune these below hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RyRM2mw_lqKw"
   },
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)\n",
    "seq_len=100\n",
    "embedding=300\n",
    "lstm_size=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tBRdqv252PBV",
    "outputId": "c07279d9-1013-4529-d3d9-1093f9982eac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pG4iiPZWlqK2"
   },
   "source": [
    "### Notice that in the tutorial it is just one step ahead and ahead, I am making seq_len steps ahead, and see what that happens\n",
    "\n",
    "It performed badly and give dumb things back, and that is because we are not giving enough data to learn from, here we are shifting the window by window size\n",
    "\n",
    "#### Another way is give enough exmaples with shift of window by 1, we are giving enough examples, but for x examples we have y examples\n",
    "So this is also working bad and poor results\n",
    "\n",
    "#### So do x examples and 1 y, so that it has lots of examples and lot to learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGp-oN5mlqK4"
   },
   "outputs": [],
   "source": [
    "def get_training_data(data,seq_len):\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    \n",
    "    for i in range(0,len(data)-seq_len,1):\n",
    "        x=data[i:i+seq_len]\n",
    "        y=data[i+seq_len]\n",
    "        \n",
    "        x_train.append(np.array(x))\n",
    "        y_train.append(np.array(y))\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sauCsvoJlqK9"
   },
   "outputs": [],
   "source": [
    "x,y =get_training_data(text_int,seq_len)\n",
    "# print(type(y))\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "# y=y.reshape(y.shape[0],y.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SIs8fUHQBsjd",
    "outputId": "d16d9c56-e300-42a0-b6e5-2db2e4ff299e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259816,)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_wioB0VVlqLD",
    "outputId": "0879e111-8411-4d5d-eeba-c8cb956fe033",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((259816, 100), (259816,))"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDAdMkQMwexk"
   },
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     x, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8piyk-EfxAlV",
    "outputId": "59b1f6ef-bfb9-46ad-dce8-ff48d935ce7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((207852, 100), (51964, 100), (207852,), (51964,))"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5xQfn_NDXd2"
   },
   "source": [
    "### Tips If model dont learn much\n",
    "\n",
    "Do normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akpd-RdLCvgE"
   },
   "source": [
    "### Change the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTyxMDNalqLJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp=Input((None,))\n",
    "\n",
    "embed=Embedding(input_dim=vocab_size,output_dim=embedding)\n",
    "lstm1=LSTM(lstm_size,return_sequences=True,return_state=True)\n",
    "lstm2=LSTM(lstm_size,return_sequences=True,return_state=True)\n",
    "lstm3=LSTM(lstm_size,return_sequences=True,return_state=True)\n",
    "dense=Dense(vocab_size)\n",
    "\n",
    "net=embed(inp)\n",
    "net, h1, c1=lstm1(net)\n",
    "net, h2, c2=lstm2(net)\n",
    "net, h3, c3=lstm3(net)\n",
    "out=dense(net)\n",
    "\n",
    "model=Model(inp,out)\n",
    "\n",
    "init_states=[Input((lstm_size,)) for i in range(6)]\n",
    "\n",
    "inference=embed(inp)\n",
    "inference, h1, c1=lstm1(inference,initial_state=init_states[:2])\n",
    "inference, h2, c2=lstm2(inference,initial_state=init_states[2:4])\n",
    "inference, h3, c3=lstm3(inference,initial_state=init_states[4:6])\n",
    "inf_out=dense(inference)\n",
    "\n",
    "states=[h1,c1,h2,c2,h3,c3]\n",
    "inf_model=Model([inp]+ init_states,[inf_out]+ states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjJwIlytGZXT"
   },
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import LSTM\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jxfN5IGxJQ08",
    "outputId": "ccf1f0a6-35e6-4624-e6d6-19b45cc82212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207852, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xgxADPH_Jx7Q"
   },
   "outputs": [],
   "source": [
    "# x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
    "# y_train = np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVSgQXfVGpBJ"
   },
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# model.add(LSTM(256,input_shape=(x_train.shape[1],x_train.shape[2]),return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SwWY5EK-yulG"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "rmsprop = optimizers.RMSprop(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzrFcaCYlqLP"
   },
   "outputs": [],
   "source": [
    "# model.optimizer.#.lr=.01\n",
    "model.compile(optimizer=rmsprop,loss='sparse_categorical_crossentropy'\n",
    "              ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDZuQ3vhlqLe"
   },
   "source": [
    "**Make validation set and change the hyper params as per best accuracy and see the things**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dUTp1-bOKnbU",
    "outputId": "ebcfbf7b-844a-4540-900e-d9d9d2889176"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207852, 100, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yc5ebDrSLu26",
    "outputId": "0ac70235-ebea-4b8e-92c6-be930c708f8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/gdrive/My Drive/ML dataSets/TV Scripting'"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrLCdRwgLffW"
   },
   "outputs": [],
   "source": [
    "filepath=base_dir+\"/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tWRswL2ClqLi",
    "outputId": "bda42562-588d-4768-b017-db1abb8481ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "207852/207852 [==============================] - 622s 3ms/step - loss: 5.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: loss improved from inf to 5.63530, saving model to /content/gdrive/My Drive/ML dataSets/TV Scripting/weights-improvement-01-5.6353.hdf5\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-41-aa95f30711bf>\", line 3, in <module>\n",
      "    ,shuffle=True) #validation_data=(x_test,y_test)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1178, in fit\n",
      "    validation_freq=validation_freq)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\", line 224, in fit_loop\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\", line 152, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\", line 719, in on_epoch_end\n",
      "    self.model.save(filepath, overwrite=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\", line 1139, in save\n",
      "    save_model(self, filepath, overwrite, include_optimizer)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\", line 415, in save_wrapper\n",
      "    save_function(obj, filepath, overwrite, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\", line 506, in save_model\n",
      "    with H5Dict(filepath, mode='w') as h5dict:\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\", line 191, in __init__\n",
      "    self.data = h5py.File(path, mode=mode)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\", line 312, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\", line 148, in make_fid\n",
      "    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 98, in h5py.h5f.create\n",
      "OSError: Unable to create file (unable to open file: name = '/content/gdrive/My Drive/ML dataSets/TV Scripting/weights-improvement-01-5.6353.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "OSError: [Errno 107] Transport endpoint is not connected\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,\n",
    "          epochs=1, batch_size=128, callbacks=callbacks_list\n",
    "          ,shuffle=True) #validation_data=(x_test,y_test)\n",
    "# model.save('model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQUaEim-9BRa"
   },
   "source": [
    "15 minutes for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOlxbQtpOgHT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fc4WHjSilqLp"
   },
   "source": [
    "When the model is finalised then extract the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1VYvb3NlqLr"
   },
   "outputs": [],
   "source": [
    "def extract_text(length,start):\n",
    "    \n",
    "    states=[np.zeros((1,lstm_size)) for i in range(6)]\n",
    "    \n",
    "    token=np.zeros((1,1))\n",
    "    token[0,0]=start\n",
    "    text=int_to_vocab[start] + ' '\n",
    "    \n",
    "    for i in range(length):\n",
    "        \n",
    "        out=inf_model.predict([token]+states)\n",
    "        word=np.argmax(out[0][0,0,:])\n",
    "        text+=int_to_vocab[word]\n",
    "        states=out[1:7]\n",
    "        token[0][0]=word\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CPv90O0lqLw"
   },
   "outputs": [],
   "source": [
    "generate_text=extract_text(100,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-MezjaO4ErV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4zFilhqlqL0"
   },
   "outputs": [],
   "source": [
    "def post_process_text(text):\n",
    "    \n",
    "    punch1=['.', ':', '!', ';', ')', ']', '?', ',', '%']\n",
    "    for i in punch1:\n",
    "        text = text.replace(' '+i, i)\n",
    "    punch2 = ['[', '(', '$']    \n",
    "    for i in punch2:\n",
    "        text = text.replace(i+' ', i)\n",
    "    punch3 = [\"'\", '-']    \n",
    "    for i in punch3:\n",
    "        text = text.replace(' '+i+' ', i)\n",
    "        \n",
    "    cleanText=\"\"\n",
    "    text = text.split('<newline>')  \n",
    "    for line in text:\n",
    "        if len(line):\n",
    "          cleanText+=line+\"\\n\"\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qn84SyHKlqL5"
   },
   "outputs": [],
   "source": [
    "print(post_process_text(generate_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plIv9wfY4tNF"
   },
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "  generate_text=extract_text(100,i)\n",
    "  print(post_process_text(generate_text))\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
